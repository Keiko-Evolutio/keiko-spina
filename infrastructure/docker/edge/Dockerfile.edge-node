# Edge Node Dockerfile
# Lightweight Processing-Node für Audio-Verarbeitung und AI-Inferenz

# =============================================================================
# Base Stage - Python Runtime mit Audio-Libraries
# =============================================================================
FROM python:3.11-slim as base

# System-Dependencies für Audio-Processing installieren
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    gcc \
    g++ \
    libasound2-dev \
    libportaudio2 \
    libportaudiocpp0 \
    portaudio19-dev \
    libfftw3-dev \
    libsndfile1-dev \
    && rm -rf /var/lib/apt/lists/*

# Python-Umgebung konfigurieren
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Arbeitsverzeichnis erstellen
WORKDIR /app

# =============================================================================
# Dependencies Stage - Python-Pakete installieren
# =============================================================================
FROM base as dependencies

# uv installieren
RUN pip install uv==0.4.18

# Dependency-Dateien kopieren
COPY backend/pyproject.toml backend/uv.lock backend/README.md ./

# Dependencies installieren
RUN uv sync --frozen --no-dev

# Audio-Processing-spezifische Pakete (bereits in pyproject.toml enthalten)
# RUN uv add scipy librosa soundfile pyaudio webrtcvad

# =============================================================================
# Development Stage - Für lokale Entwicklung
# =============================================================================
FROM dependencies as development

# Development-Dependencies installieren
RUN uv sync --frozen

# Backend-Code kopieren
COPY backend/ ./backend/

# Edge-Node-spezifische Konfiguration
COPY infrastructure/docker/edge/config/edge-node.yml ./config/edge-node.yml

# AI-Modelle-Verzeichnis erstellen
RUN mkdir -p /app/models /app/cache /app/logs

# Beispiel-Modelle kopieren (für Development)
COPY infrastructure/docker/edge/models/ ./models/

# Health Check Script
COPY infrastructure/docker/edge/scripts/health-check.sh ./health-check.sh
RUN chmod +x ./health-check.sh

# Ports exponieren
EXPOSE 8080 8081

# Environment Variables
ENV PYTHONPATH=/app \
    EDGE_CONFIG_PATH=/app/config/edge-node.yml \
    MODELS_PATH=/app/models \
    CACHE_PATH=/app/cache \
    LOG_LEVEL=DEBUG

# Startup-Script
COPY infrastructure/docker/edge/scripts/start-edge-node.sh ./start.sh
RUN chmod +x ./start.sh

# Health Check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=5 \
    CMD ./health-check.sh edge-node 8081

# Command
CMD ["./start.sh"]

# =============================================================================
# Production Stage - Optimiert für Production
# =============================================================================
FROM dependencies as production

# Nur Production-Code kopieren
COPY backend/edge/ ./backend/edge/
COPY backend/kei_logging.py ./backend/kei_logging.py
COPY backend/__init__.py ./backend/__init__.py

# Edge-Node-spezifische Dateien
COPY infrastructure/docker/edge/config/edge-node.prod.yml ./config/edge-node.yml
COPY infrastructure/docker/edge/scripts/start-edge-node.sh ./start.sh
COPY infrastructure/docker/edge/scripts/health-check.sh ./health-check.sh

# Production-Modelle kopieren
COPY infrastructure/docker/edge/models/production/ ./models/

RUN chmod +x ./start.sh ./health-check.sh

# Verzeichnisse erstellen
RUN mkdir -p /app/cache /app/logs

# Non-root User erstellen
RUN groupadd -r edge && useradd -r -g edge edge
RUN chown -R edge:edge /app
USER edge

# Ports exponieren
EXPOSE 8080 8081

# Environment Variables
ENV PYTHONPATH=/app \
    EDGE_CONFIG_PATH=/app/config/edge-node.yml \
    MODELS_PATH=/app/models \
    CACHE_PATH=/app/cache \
    LOG_LEVEL=INFO

# Health Check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=5 \
    CMD ./health-check.sh edge-node 8081

# Command
CMD ["./start.sh"]

# =============================================================================
# GPU-Enabled Stage - Für AI-Inferenz mit GPU-Unterstützung
# =============================================================================
FROM nvidia/cuda:11.8-runtime-ubuntu22.04 as gpu

# Python installieren
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3.11-pip \
    python3.11-venv \
    curl \
    wget \
    gcc \
    g++ \
    libasound2-dev \
    libportaudio2 \
    libfftw3-dev \
    libsndfile1-dev \
    && rm -rf /var/lib/apt/lists/*

# Python-Symlinks erstellen
RUN ln -s /usr/bin/python3.11 /usr/bin/python
RUN ln -s /usr/bin/pip3 /usr/bin/pip

# Arbeitsverzeichnis
WORKDIR /app

# Python-Umgebung
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1

# Poetry installieren
RUN pip install poetry==1.6.1

# Dependencies kopieren und installieren
COPY pyproject.toml poetry.lock ./
RUN poetry install --only=main --no-root

# GPU-spezifische Pakete
RUN poetry run pip install \
    torch==2.0.1+cu118 \
    torchaudio==2.0.2+cu118 \
    --index-url https://download.pytorch.org/whl/cu118

# Backend-Code kopieren
COPY backend/edge/ ./backend/edge/
COPY backend/kei_logging.py ./backend/kei_logging.py

# GPU-optimierte Konfiguration
COPY infrastructure/docker/edge/config/edge-node.gpu.yml ./config/edge-node.yml
COPY infrastructure/docker/edge/scripts/start-edge-node.sh ./start.sh
COPY infrastructure/docker/edge/scripts/health-check.sh ./health-check.sh

# GPU-optimierte Modelle
COPY infrastructure/docker/edge/models/gpu/ ./models/

RUN chmod +x ./start.sh ./health-check.sh
RUN mkdir -p /app/cache /app/logs

# Environment Variables
ENV PYTHONPATH=/app \
    EDGE_CONFIG_PATH=/app/config/edge-node.yml \
    MODELS_PATH=/app/models \
    CACHE_PATH=/app/cache \
    CUDA_VISIBLE_DEVICES=0 \
    LOG_LEVEL=INFO

# Ports exponieren
EXPOSE 8080 8081

# Health Check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=5 \
    CMD ./health-check.sh edge-node 8081

# Command
CMD ["./start.sh"]
